import pandas as pd
import toml
import os
from src.pipelines.xgb import train_and_save, inference  # ç¡®ä¿è¯¥æ¨¡å—å·²ä¿å­˜ä¸º train_model.py
from src.utils import load_artifacts, calculate_confidence_intervals

# # === åŠ è½½é…ç½®æ–‡ä»¶ ===
config = toml.load("config/xgb.toml")
# model, scaler, pca, X_train, X_test, y_train, y_test = load_artifacts(config)

# print(X_test.columns)

# # === è®­ç»ƒæ¨¡å‹ ===
if not os.path.exists(config['output']['model_path']):
# if True:
    data_path = config['input']['data_path']
    df = pd.read_csv(data_path)
    train_and_save(df, config)
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå·²ä¿å­˜æ¨¡å‹ä¸PCA/Scaler æ–‡ä»¶ã€‚")


# === ç¤ºä¾‹è¾“å…¥ï¼šæ¥è‡ªä¸€ä¸ª dict ===
input_dict = {
    'PRODUCT': 'P123',
    'SALESYEAR': 2024,
    'RELEASE_YEAR': 2020,
    'DISEASE_RESISTANCE': 3,
    'INSECT_RESISTANCE': 4,
    'PROTECTION': 2,
    'DROUGHT_TOLERANCE': 5.0,
    'BRITTLE_STALK': None,        # å¯ç¼ºå¤±
    'PLANT_HEIGHT': 6.0,
    'RELATIVE_MATURITY': 3,
    'STATE': 'Texas',
    'LIFECYCLE': 'EXPANSION'
}

# === è½¬ä¸º DataFrame ===
input_df = pd.DataFrame([input_dict])

# === è°ƒç”¨æ¨ç†å‡½æ•° ===
prediction = inference(input_df, config)

print(f"ğŸ”® é¢„æµ‹é”€é‡ï¼ˆUNITSï¼‰ä¸º: {prediction[0]:.2f}")
