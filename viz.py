import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import shap
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import MinMaxScaler

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="XGBoostæ¨¡å‹åˆ†æä»ªè¡¨æ¿",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ ‡é¢˜å’Œæè¿°
st.title("ğŸš€ XGBoostæ¨¡å‹å¯è§†åŒ–åˆ†æä»ªè¡¨æ¿")
st.markdown("---")

# ä¾§è¾¹æ é…ç½®
st.sidebar.title("âš™ï¸ æ¨¡å‹é…ç½®")

# é€‰æ‹©æ•°æ®é›†
dataset_choice = st.sidebar.selectbox(
    "é€‰æ‹©æ•°æ®é›†",
    ["Seed Production", "æ¨¡æ‹Ÿå›å½’æ•°æ®"]
)

# æ¨¡å‹å‚æ•°é…ç½®
st.sidebar.subheader("XGBoostå‚æ•°")
n_estimators = st.sidebar.slider("n_estimators", 50, 500, 100)
max_depth = st.sidebar.slider("max_depth", 3, 10, 6)
learning_rate = st.sidebar.slider("learning_rate", 0.01, 0.3, 0.1)

@st.cache_data
def load_data(choice):
    """åŠ è½½æ•°æ®é›†"""
    df = pd.read_csv('case_study_data.csv')
    df['idx'] = df.index  # Save original index
    df['Years_Since_Release'] = df['SALESYEAR'] - df['RELEASE_YEAR']

    # One-hot encode categorical variables
    df_encoded = pd.get_dummies(df, columns=['STATE', 'LIFECYCLE'])
    ordinal_cols = ['DROUGHT_TOLERANCE', 'BRITTLE_STALK', 'PLANT_HEIGHT', 'RELATIVE_MATURITY']
    scaler = MinMaxScaler()
    df_encoded[ordinal_cols] = scaler.fit_transform(df_encoded[ordinal_cols])
    df_encoded = df_encoded.drop(columns=['PRODUCT', 'RELEASE_YEAR'])
    if 'Lifecycle Stage_Phaseout' in df_encoded.columns:
        df_encoded = df_encoded[df_encoded['Lifecycle Stage_Phaseout'] == 0]
        df_encoded = df_encoded.drop(columns=['Lifecycle Stage_Phaseout'])
    X = df_encoded.drop(columns=['UNITS','idx'])
    # print(X.dtypes) # bool cann't be used in TreeExplainer compute
    y = df_encoded['UNITS']

    # if choice == "æ³¢å£«é¡¿æˆ¿ä»·":
    #     # ä½¿ç”¨sklearnçš„make_regressionåˆ›å»ºç±»ä¼¼çš„æ•°æ®é›†
    #     X, y = make_regression(n_samples=506, n_features=13, noise=10, random_state=42)
    #     feature_names = [f'feature_{i}' for i in range(13)]
    #     X = pd.DataFrame(X, columns=feature_names)
    #     y = pd.Series(y, name='target')
    # else:
    #     X, y = make_regression(n_samples=1000, n_features=10, noise=5, random_state=42)
    #     feature_names = [f'feature_{i}' for i in range(10)]
    #     X = pd.DataFrame(X, columns=feature_names)
    #     y = pd.Series(y, name='target')
    
    return X, y

@st.cache_data
def train_model(X, y, n_est, max_d, lr):
    """è®­ç»ƒXGBoostæ¨¡å‹"""
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = xgb.XGBRegressor(
        n_estimators=n_est,
        max_depth=max_d,
        learning_rate=lr,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    return model, X_train, X_test, y_train, y_test, y_pred_train, y_pred_test

def calculate_confidence_intervals(model, X_test, y_test, confidence=0.95):
    """è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆä½¿ç”¨è‡ªåŠ©æ³•ä¼°è®¡ï¼‰"""
    predictions = []
    n_bootstrap = 100
    
    # è·å–è®­ç»ƒæ•°æ®çš„ç´¢å¼•
    n_samples = len(X_test)
    
    for _ in range(n_bootstrap):
        # è‡ªåŠ©é‡‡æ ·
        indices = np.random.choice(n_samples, n_samples, replace=True)
        X_bootstrap = X_test.iloc[indices]
        
        # é¢„æµ‹
        pred = model.predict(X_bootstrap)
        predictions.append(pred)
    
    predictions = np.array(predictions)
    
    # è®¡ç®—ç½®ä¿¡åŒºé—´
    alpha = 1 - confidence
    lower_percentile = (alpha/2) * 100
    upper_percentile = (1 - alpha/2) * 100
    
    lower_bound = np.percentile(predictions, lower_percentile, axis=0)
    upper_bound = np.percentile(predictions, upper_percentile, axis=0)
    
    return lower_bound, upper_bound

# åŠ è½½æ•°æ®å’Œè®­ç»ƒæ¨¡å‹
X, y = load_data(dataset_choice)
model, X_train, X_test, y_train, y_test, y_pred_train, y_pred_test = train_model(
    X, y, n_estimators, max_depth, learning_rate
)

# ä¸»è¦å†…å®¹åŒºåŸŸ
col1, col2 = st.columns(2)

# 1. è¯„ä¼°æŒ‡æ ‡
with col1:
    st.subheader("ğŸ“ˆ æ¨¡å‹è¯„ä¼°æŒ‡æ ‡")
    
    # è®¡ç®—æŒ‡æ ‡
    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    train_r2 = r2_score(y_train, y_pred_train)
    test_r2 = r2_score(y_test, y_pred_test)
    train_mae = mean_absolute_error(y_train, y_pred_train)
    test_mae = mean_absolute_error(y_test, y_pred_test)
    
    # åˆ›å»ºæŒ‡æ ‡è¡¨æ ¼
    metrics_df = pd.DataFrame({
        'æŒ‡æ ‡': ['RMSE', 'RÂ²', 'MAE'],
        'è®­ç»ƒé›†': [f'{train_rmse:.3f}', f'{train_r2:.3f}', f'{train_mae:.3f}'],
        'æµ‹è¯•é›†': [f'{test_rmse:.3f}', f'{test_r2:.3f}', f'{test_mae:.3f}']
    })
    
    st.dataframe(metrics_df, use_container_width=True)
    
    # é¢„æµ‹vså®é™…å€¼æ•£ç‚¹å›¾
    fig_scatter = go.Figure()
    
    fig_scatter.add_trace(go.Scatter(
        x=y_test, y=y_pred_test,
        mode='markers',
        name='æµ‹è¯•é›†',
        marker=dict(color='blue', opacity=0.6)
    ))
    
    # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
    min_val = min(y_test.min(), y_pred_test.min())
    max_val = max(y_test.max(), y_pred_test.max())
    fig_scatter.add_trace(go.Scatter(
        x=[min_val, max_val],
        y=[min_val, max_val],
        mode='lines',
        name='å®Œç¾é¢„æµ‹',
        line=dict(color='red', dash='dash')
    ))
    
    fig_scatter.update_layout(
        title='é¢„æµ‹å€¼ vs å®é™…å€¼',
        xaxis_title='å®é™…å€¼',
        yaxis_title='é¢„æµ‹å€¼',
        height=400
    )
    
    st.plotly_chart(fig_scatter, use_container_width=True)

# 2. ç‰¹å¾é‡è¦æ€§
with col2:
    st.subheader("ğŸ¯ ç‰¹å¾é‡è¦æ€§")
    
    # è·å–ç‰¹å¾é‡è¦æ€§
    importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=True)
    
    # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
    fig_importance = px.bar(
        importance_df,
        x='importance',
        y='feature',
        orientation='h',
        title='ç‰¹å¾é‡è¦æ€§æ’åº',
        height=400
    )
    
    fig_importance.update_layout(
        xaxis_title='é‡è¦æ€§åˆ†æ•°',
        yaxis_title='ç‰¹å¾'
    )
    
    st.plotly_chart(fig_importance, use_container_width=True)

# 3. ç½®ä¿¡åŒºé—´åˆ†æ
st.subheader("ğŸ“Š é¢„æµ‹ç½®ä¿¡åŒºé—´åˆ†æ")

col3, col4 = st.columns(2)

with col3:
    confidence_level = st.slider("ç½®ä¿¡æ°´å¹³", 0.8, 0.99, 0.95, 0.01)

with col4:
    n_samples_to_show = st.slider("æ˜¾ç¤ºæ ·æœ¬æ•°", 10, 50, 20)

# è®¡ç®—ç½®ä¿¡åŒºé—´
lower_bound, upper_bound = calculate_confidence_intervals(model, X_test, y_test, confidence_level)

# é€‰æ‹©è¦æ˜¾ç¤ºçš„æ ·æœ¬
indices_to_show = np.random.choice(len(y_test), n_samples_to_show, replace=False)
indices_to_show = sorted(indices_to_show)

# åˆ›å»ºç½®ä¿¡åŒºé—´å›¾
fig_ci = go.Figure()

# æ·»åŠ ç½®ä¿¡åŒºé—´
fig_ci.add_trace(go.Scatter(
    x=list(range(len(indices_to_show))),
    y=upper_bound[indices_to_show],
    fill=None,
    mode='lines',
    line_color='rgba(0,100,80,0)',
    showlegend=False
))

fig_ci.add_trace(go.Scatter(
    x=list(range(len(indices_to_show))),
    y=lower_bound[indices_to_show],
    fill='tonexty',
    mode='lines',
    line_color='rgba(0,100,80,0)',
    name=f'{confidence_level*100:.0f}% ç½®ä¿¡åŒºé—´',
    fillcolor='rgba(0,100,80,0.2)'
))

# æ·»åŠ é¢„æµ‹å€¼
fig_ci.add_trace(go.Scatter(
    x=list(range(len(indices_to_show))),
    y=y_pred_test[indices_to_show],
    mode='markers+lines',
    name='é¢„æµ‹å€¼',
    line=dict(color='blue')
))

# æ·»åŠ å®é™…å€¼
fig_ci.add_trace(go.Scatter(
    x=list(range(len(indices_to_show))),
    y=y_test.iloc[indices_to_show],
    mode='markers',
    name='å®é™…å€¼',
    marker=dict(color='red', size=8)
))

fig_ci.update_layout(
    title=f'é¢„æµ‹ç½®ä¿¡åŒºé—´ (ç½®ä¿¡æ°´å¹³: {confidence_level*100:.0f}%)',
    xaxis_title='æ ·æœ¬ç´¢å¼•',
    yaxis_title='å€¼',
    height=500
)

st.plotly_chart(fig_ci, use_container_width=True)

# 4. SHAPåˆ†æ
st.subheader("ğŸ” SHAPå¯è§£é‡Šæ€§åˆ†æ")

# è®¡ç®—SHAPå€¼
@st.cache_data
def calculate_shap_values(_model, _X_train, _X_test):
    explainer = shap.TreeExplainer(_model)
    shap_values_train = explainer.shap_values(_X_train)
    shap_values_test = explainer.shap_values(_X_test)
    return explainer, shap_values_train, shap_values_test

try:
    explainer, shap_values_train, shap_values_test = calculate_shap_values(model, X_train, X_test)
    shap_success = True
except Exception as e:
    st.error(f"SHAPè®¡ç®—å¤±è´¥: {str(e)}")
    st.info("å°†ä½¿ç”¨æ¨¡å‹å†…ç½®çš„ç‰¹å¾é‡è¦æ€§ä½œä¸ºæ›¿ä»£")
    shap_success = False

if shap_success:

    # SHAPæ±‡æ€»å›¾
    col5, col6 = st.columns(2)

    with col5:
        st.subheader("SHAPæ±‡æ€»å›¾")
        
        fig_shap_summary, ax = plt.subplots(figsize=(10, 6))
        shap.summary_plot(shap_values_test, X_test, show=False, max_display=10)
        st.pyplot(fig_shap_summary, bbox_inches='tight')
        plt.close()

    with col6:
        st.subheader("SHAPç‰¹å¾é‡è¦æ€§")
        
        fig_shap_bar, ax = plt.subplots(figsize=(10, 6))
        shap.summary_plot(shap_values_test, X_test, plot_type="bar", show=False, max_display=10)
        st.pyplot(fig_shap_bar, bbox_inches='tight')
        plt.close()

    # 5. å•ä¸ªé¢„æµ‹çš„SHAPè§£é‡Š
    st.subheader("ğŸ¯ å•ä¸ªé¢„æµ‹çš„SHAPè§£é‡Š")

    sample_idx = st.selectbox(
        "é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬ç´¢å¼•",
        range(min(20, len(X_test)))
    )

    col7, col8 = st.columns(2)

    with col7:
        # æ˜¾ç¤ºæ ·æœ¬ä¿¡æ¯
        st.write("**æ ·æœ¬ç‰¹å¾å€¼:**")
        sample_features = X_test.iloc[sample_idx]
        feature_df = pd.DataFrame({
            'ç‰¹å¾': sample_features.index,
            'å€¼': sample_features.values
        })
        st.dataframe(feature_df)
        
        # é¢„æµ‹ç»“æœ
        prediction = y_pred_test[sample_idx]
        actual = y_test.iloc[sample_idx]
        st.write(f"**é¢„æµ‹å€¼:** {prediction:.3f}")
        st.write(f"**å®é™…å€¼:** {actual:.3f}")
        st.write(f"**è¯¯å·®:** {abs(prediction - actual):.3f}")

    with col8:
        # SHAPç€‘å¸ƒå›¾
        st.write("**SHAPè§£é‡Š (ç€‘å¸ƒå›¾):**")
        
        try:
            # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬SHAPçš„waterfall_plot
            fig_waterfall, ax = plt.subplots(figsize=(10, 8))
            
            # åˆ›å»ºExplanationå¯¹è±¡ (é€‚ç”¨äºæ–°ç‰ˆSHAP)
            if hasattr(shap, 'Explanation'):
                explanation = shap.Explanation(
                    values=shap_values_test[sample_idx],
                    base_values=explainer.expected_value,
                    data=X_test.iloc[sample_idx].values,
                    feature_names=X_test.columns.tolist()
                )
                shap.waterfall_plot(explanation, show=False)
            else:
                # é™çº§åˆ°æ—§ç‰ˆæœ¬API
                shap.waterfall_plot(
                    explainer.expected_value, 
                    shap_values_test[sample_idx], 
                    X_test.iloc[sample_idx]
                )
            
            st.pyplot(fig_waterfall, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            # å¦‚æœç€‘å¸ƒå›¾å¤±è´¥ï¼Œä½¿ç”¨åŠ›å›¾ä½œä¸ºæ›¿ä»£
            st.write("**SHAPè§£é‡Š (åŠ›å›¾):**")
            fig_force, ax = plt.subplots(figsize=(12, 6))
            
            # åˆ›å»ºforce plot
            force_plot = shap.force_plot(
                explainer.expected_value,
                shap_values_test[sample_idx],
                X_test.iloc[sample_idx],
                matplotlib=True,
                show=False
            )
            
            st.pyplot(fig_force, bbox_inches='tight')
            plt.close()
            
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            with st.expander("è°ƒè¯•ä¿¡æ¯"):
                st.write(f"ç€‘å¸ƒå›¾é”™è¯¯: {str(e)}")
                st.write("å·²ä½¿ç”¨åŠ›å›¾ä½œä¸ºæ›¿ä»£å¯è§†åŒ–")

    # 6. ç‰¹å¾é©±åŠ¨å› å­åˆ†æ
    st.subheader("ğŸ“‹ ç‰¹å¾é©±åŠ¨å› å­åˆ†æ")

    # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡SHAPå€¼è´¡çŒ®
    feature_contributions = pd.DataFrame({
        'feature': X_test.columns,
        'mean_shap_abs': np.abs(shap_values_test).mean(0),
        'mean_shap': shap_values_test.mean(0)
    })

    feature_contributions = feature_contributions.sort_values('mean_shap_abs', ascending=False)

    # åˆ›å»ºé©±åŠ¨å› å­å›¾
    fig_drivers = px.bar(
        feature_contributions.head(10),
        x='mean_shap',
        y='feature',
        orientation='h',
        title='Top 10 ç‰¹å¾é©±åŠ¨å› å­ (å¹³å‡SHAPå€¼)',
        color='mean_shap',
        color_continuous_scale='RdBu_r'
    )

    fig_drivers.update_layout(height=500)
    st.plotly_chart(fig_drivers, use_container_width=True)

    # 7. æ¨¡å‹æ€§èƒ½æ€»ç»“
    st.subheader("ğŸ“ æ¨¡å‹æ€§èƒ½æ€»ç»“")

    summary_col1, summary_col2, summary_col3 = st.columns(3)

    with summary_col1:
        st.metric("æµ‹è¯•é›†RÂ²", f"{test_r2:.3f}")
        st.metric("æµ‹è¯•é›†RMSE", f"{test_rmse:.3f}")

    with summary_col2:
        st.metric("æœ€é‡è¦ç‰¹å¾", feature_contributions.iloc[0]['feature'])
        st.metric("ç‰¹å¾æ•°é‡", len(X.columns))

    with summary_col3:
        st.metric("è®­ç»ƒæ ·æœ¬æ•°", len(X_train))
        st.metric("æµ‹è¯•æ ·æœ¬æ•°", len(X_test))

    # 8. æ•°æ®ä¸‹è½½
    st.subheader("ğŸ’¾ ç»“æœä¸‹è½½")

    col9, col10 = st.columns(2)

    with col9:
        # å‡†å¤‡é¢„æµ‹ç»“æœæ•°æ®
        results_df = pd.DataFrame({
            'actual': y_test,
            'predicted': y_pred_test,
            'lower_bound': lower_bound[:len(y_test)],
            'upper_bound': upper_bound[:len(y_test)]
        })
        
        csv_results = results_df.to_csv(index=False)
        st.download_button(
            "ä¸‹è½½é¢„æµ‹ç»“æœ",
            csv_results,
            "predictions.csv",
            "text/csv"
        )

    with col10:
        if shap_success:
            # å‡†å¤‡SHAPå€¼æ•°æ®
            shap_df = pd.DataFrame(shap_values_test, columns=X_test.columns)
            csv_shap = shap_df.to_csv(index=False)
            
            st.download_button(
                "ä¸‹è½½SHAPå€¼",
                csv_shap,
                "shap_values.csv",
                "text/csv"
            )
        else:
            # å¦‚æœSHAPå¤±è´¥ï¼Œæä¾›ç‰¹å¾é‡è¦æ€§æ•°æ®
            importance_df = pd.DataFrame({
                'feature': X.columns,
                'importance': model.feature_importances_
            })
            csv_importance = importance_df.to_csv(index=False)
            
            st.download_button(
                "ä¸‹è½½ç‰¹å¾é‡è¦æ€§",
                csv_importance,
                "feature_importance.csv",
                "text/csv"
            )

    # é¡µè„š
    st.markdown("---")
    st.markdown("*æ­¤åº”ç”¨å±•ç¤ºäº†XGBoostæ¨¡å‹çš„å…¨é¢åˆ†æï¼ŒåŒ…æ‹¬æ€§èƒ½è¯„ä¼°ã€ç‰¹å¾é‡è¦æ€§ã€ç½®ä¿¡åŒºé—´å’Œå¯è§£é‡Šæ€§åˆ†æã€‚*")